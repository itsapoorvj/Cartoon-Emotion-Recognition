{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIP_term_project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1vRymTAtgns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install scipy==1.1.0 --user"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezK-hKtfyyBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt-get install dvipng texlive-latex-extra texlive-fonts-recommended  \n",
        "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip \n",
        "! unzip type1cm.zip -d /tmp/type1cm \n",
        "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins\n",
        "! sudo mkdir /usr/share/texmf/tex/latex/type1cm \n",
        "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm \n",
        "! sudo texhash \n",
        "!apt install cm-super"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6k1CfLL66CA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE8dqdbwEJHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "from keras.utils import to_categorical as one_hot\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras import optimizers\n",
        "\n",
        "from vis.utils import utils\n",
        "from vis.visualization import visualize_activation, visualize_saliency, get_num_filters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwryfqzXnAS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT-JVx2_fz8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend.tensorflow_backend as tfback\n",
        "import tensorflow as tf\n",
        "\n",
        "def _get_available_gpus():\n",
        "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
        "\n",
        "    # Returns\n",
        "        A list of available GPU devices.\n",
        "    \"\"\"\n",
        "    #global _LOCAL_DEVICES\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmYhVSQGEZNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_version = \"v1.6\"\n",
        "emotions = [\"happy\", \"angry\", \"surprise\", \"sad\", \"fear\", \"disgust\"]\n",
        "w, h = (60, 60)\n",
        "epochs = 50\n",
        "\n",
        "COLOR = {\n",
        "\t'G':'\\x1B[32m',\n",
        "\t'R':'\\x1B[31m',\n",
        "\t'RS':'\\x1B[0m'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0JVzesEc9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PlotStats callback for printing custom plot stats of the model.\n",
        "class PlotStats(Callback):\n",
        "\tdef on_train_end(self, logs={}):\n",
        "\t\t# model loss plot.\n",
        "\t\tplt.plot(self.losses)\n",
        "\t\tplt.plot(self.val_losses,  color=\"green\")\n",
        "\t\tplt.title('Learning curve for model loss')\n",
        "\t\tplt.ylabel('loss')\n",
        "\t\tplt.xlabel('epochs ({})'.format(epochs))\n",
        "\t\tplt.legend(['training', 'testing'], loc='upper left')\n",
        "\t\tplt.savefig('model_{}_loss.png'.format(model_version))\n",
        "\t\tplt.gcf().clf()\n",
        "\t\t\n",
        "\t\t# model accuracy plot.\n",
        "\t\tplt.plot(self.acc)\n",
        "\t\tplt.plot(self.val_acc,  color=\"green\")\n",
        "\t\tplt.title('Learning curve for model accuracy'.format(epochs))\n",
        "\t\tplt.ylabel('accuracy')\n",
        "\t\tplt.xlabel('epochs ({})'.format(epochs))\n",
        "\t\tplt.legend(['training', 'testing'], loc='upper left')\n",
        "\t\tplt.savefig('model_{}_accuracy.png'.format(model_version))\n",
        "\t\tplt.gcf().clf()\n",
        "\t\t\n",
        "\tdef on_train_begin(self, logs={}):\n",
        "\t\tself.losses = []\n",
        "\t\tself.acc = []\n",
        "\t\tself.val_acc = []\n",
        "\t\tself.val_losses = []\n",
        "\n",
        "\tdef on_epoch_end(self, batch, logs={}):\n",
        "\t\tself.losses.append(logs.get('loss'))\n",
        "\t\tself.val_losses.append(logs.get('val_loss'))\t\t\n",
        "\t\tself.acc.append(logs.get('acc'))\n",
        "\t\tself.val_acc.append(logs.get('val_acc'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6luxgl6EgU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loads the emotion datasets and constructs them into numpy arrays \n",
        "# for training & testing for a character.\n",
        "def load_emotion_data_for(character):\n",
        "\tDATASETS = {\n",
        "\t\t'happy': {\n",
        "\t\t\t'training':'/content/drive/My Drive/datasets/' + character + '/happy/training',\n",
        "\t\t\t'testing':'/content/drive/My Drive/datasets/'  + character + '/happy/testing',\n",
        "\t\t},\n",
        "\t\t'angry': {\n",
        "\t\t\t'training':'/content/drive/My Drive/datasets/' + character + '/angry/training',\n",
        "\t\t\t'testing':'/content/drive/My Drive/datasets/'  + character + '/angry/testing',\n",
        "\t\t},\n",
        "\t\t'surprise': {\n",
        "\t\t\t'training':'/content/drive/My Drive/datasets/' + character + '/surprise/training',\n",
        "\t\t\t'testing':'/content/drive/My Drive/datasets/'  + character + '/surprise/testing',\n",
        "\t\t}\n",
        "\t}\n",
        "\temotions_training = []\n",
        "\temotions_testing = []\n",
        "\n",
        "\t# training\n",
        "\t# append paths for happy training...\n",
        "\tfor hd_train in os.listdir(DATASETS['happy']['training']):\n",
        "\t\temotions_training.append(os.path.join(DATASETS['happy']['training'], hd_train))\n",
        "\t\t\n",
        "\t# append paths for angry training...\n",
        "\tfor ad_train in os.listdir(DATASETS['angry']['training']):\n",
        "\t\temotions_training.append(os.path.join(DATASETS['angry']['training'], ad_train))\n",
        "\t\n",
        "\t# Append paths for surprise training...\n",
        "\tfor sp_train in os.listdir(DATASETS['surprise']['training']):\n",
        "\t\temotions_training.append(os.path.join(DATASETS['surprise']['training'], sp_train))\n",
        "\t\n",
        "\t# todo: append paths for other emotions for training...\n",
        "\t# ...\n",
        "\t\n",
        "\t# testing\n",
        "\t# append paths for happy testing...\n",
        "\tfor hd_test in os.listdir(DATASETS['happy']['testing']):\n",
        "\t\temotions_testing.append(os.path.join(DATASETS['happy']['testing'], hd_test))\n",
        "\t\t\n",
        "\t# append paths for angry testing...\n",
        "\tfor ad_test in os.listdir(DATASETS['angry']['testing']):\n",
        "\t\temotions_testing.append(os.path.join(DATASETS['angry']['testing'], ad_test))\n",
        "\t\n",
        "\t# append paths for surprise testing...\n",
        "\tfor sp_test in os.listdir(DATASETS['surprise']['testing']):\n",
        "\t\temotions_testing.append(os.path.join(DATASETS['surprise']['testing'], sp_test))\n",
        "\t\t\n",
        "\t# todo: append paths for other emotions for testing...\n",
        "\t# ...\n",
        "\t\n",
        "\tdata_size = len(emotions_training) // len(DATASETS.keys())\n",
        "\t\n",
        "\t# labels\n",
        "\t# happy labels / label 0\n",
        "\thappy_labels_train = np.zeros(data_size)\n",
        "\thappy_labels_test = np.zeros(data_size)\t\n",
        "\t\n",
        "\t# angry labels / label 1 (fill with ones)\n",
        "\tangry_labels_train = np.zeros(data_size)\n",
        "\tangry_labels_train.fill(1)\n",
        "\tangry_labels_test = np.zeros(data_size)\n",
        "\tangry_labels_test.fill(1)\n",
        "\t\n",
        "\t# surprise labels / label 2 (fill with ones)\n",
        "\tsurprise_labels_train = np.zeros(data_size)\n",
        "\tsurprise_labels_train.fill(2)\n",
        "\tsurprise_labels_test = np.zeros(data_size)\n",
        "\tsurprise_labels_test.fill(2)\n",
        "\t\n",
        "\t# todo: other emotion labels / label n (fill with n's) (see the emotion array)\n",
        "\t# ...\n",
        "\t\n",
        "\t# append training & testing emotion labels.\n",
        "\temotion_training_labels = np.append(happy_labels_train, angry_labels_train)\n",
        "\temotion_training_labels = np.append(emotion_training_labels, surprise_labels_train)\n",
        "\t\n",
        "\temotion_testing_labels = np.append(happy_labels_test, angry_labels_test)\n",
        "\temotion_testing_labels = np.append(emotion_testing_labels, surprise_labels_test)\n",
        "\t\n",
        "\tprint (\"(training) loaded {} images & {} labels for {}...\".format(len(emotions_training), len(emotion_training_labels), character))\n",
        "\tprint (\"(testing) loaded {} images & {} labels for {}...\".format(len(emotions_testing), len(emotion_testing_labels), character))\n",
        "\t\n",
        "\treturn (emotions_training, emotion_training_labels), (emotions_testing, emotion_testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVu7q1f4EoiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# process images into numpy for training & testing.\n",
        "def process_images(fp):\n",
        "\timgs = []\n",
        "\tfor f in fp:\n",
        "\t\timg = load_img(f)\n",
        "\t\timg = img.resize((w,h), Image.ANTIALIAS)\n",
        "\t\timg = img_to_array(img) / 255\n",
        "\t\timg = img.reshape(3, w, h)\n",
        "\t\timgs.append(img)\n",
        "\treturn np.array(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJS_eOWDErmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display an image with a or without a label in matplotlib.\n",
        "def show_image(i, l=None):\n",
        "\tplt.imshow(array_to_img(i[0].reshape(3, w, h)))\n",
        "\tif l is not None:\n",
        "\t\tprint (\"label: {}\".format(emotions[np.argmax(l[0])]))\n",
        "\tplt.axis('off')\n",
        "\tplt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0jQMQhWEuCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetches a random image from a given dataset.\n",
        "# returns a numpy image, the original image and the ground truth label.\n",
        "def random_image_from_dataset(i, gtl):\n",
        "\tri = np.random.choice(len(i))\n",
        "\tnumpy_img = i[ri]\n",
        "\torig = array_to_img(numpy_img.reshape(3, w, h))\n",
        "\tnumpy_img = i[ri].reshape(1, 3, w, h)\n",
        "\treturn numpy_img, orig, gtl[ri]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSQijJ2mEwEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configuration before classification and training.\n",
        "def setup(reproduce=True):\n",
        "\t# fix the seed to reproduce results in this dissertation.\n",
        "\tseed = 12379231\n",
        "\tif reproduce is True:\n",
        "\t\tnp.random.seed(seed)\n",
        "\tplt.rc('text', usetex=True)\n",
        "\tplt.rc('font', family='serif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl_SZY5iE2-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main dataset loader for tom and jerry.\n",
        "def load_dataset():\n",
        "\ttom_training, tom_testing = load_emotion_data_for(\"tom\")\n",
        "\tjerry_training, jerry_testing = load_emotion_data_for(\"jerry\")\n",
        "\t\n",
        "\ttraining_i = np.append(tom_training[0], jerry_training[0])\n",
        "\ttraining_l = np.append(tom_training[1], jerry_training[1])\n",
        "\t\n",
        "\ttesting_i = np.append(tom_testing[0], jerry_testing[0])\n",
        "\ttraining_l = np.append(tom_testing[1], jerry_testing[1])\n",
        "\t\n",
        "\treturn (training_i, training_l), (testing_i, training_l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEnyC0pYE55E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# perform training.\n",
        "def load_training_and_testing_data():\n",
        "\tprint ( \"loading training & testing data...\")\n",
        "\ttraining, testing = load_dataset()\n",
        "\n",
        "\t# process testing and training images -> numpy arrays.\n",
        "\ttrain_images = process_images(training[0])\n",
        "\ttest_images = process_images(testing[0])\n",
        "\t\n",
        "\t# convert training and testing to one hot vectors.\n",
        "\ttrain_labels = one_hot(training[1], num_classes=6)\n",
        "\ttest_labels = one_hot(testing[1], num_classes=6)\n",
        "\t\n",
        "\t# shuffle training data in sync for better training.\n",
        "\trng = np.random.get_state()\n",
        "\tnp.random.shuffle(train_images)\n",
        "\tnp.random.set_state(rng)\n",
        "\tnp.random.shuffle(train_labels)\n",
        "\t\n",
        "\t# partition dataset 80/20. (80 -> training, 20 -> testing)\n",
        "\tr = np.random.rand(train_images.shape[0])\n",
        "\tpart = r < np.percentile(r, 80)\n",
        "\ttrain_images = train_images[part]\n",
        "\ttrain_labels = train_labels[part]\n",
        "\ttest_images = test_images[~part]\n",
        "\ttest_labels = test_labels[~part]\n",
        "\t\n",
        "\t# optionally show images and labels.\n",
        "\t# show_image(train_images, train_labels)\n",
        "\t# show_image(test_images, test_labels)\n",
        "\treturn train_images, train_labels, test_images, test_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIf0QEwFE_rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train images and test labels.\n",
        "def train(train_i, train_l, test_i, test_l, visualise, summary):\n",
        "\t# load our cnn model.\n",
        "\tcnn = load_cnn_model()\n",
        "\t\n",
        "\t# begin training and save the model when finished.\n",
        "\tif not os.path.isfile('model_{}_.h5'.format(model_version)):\n",
        "\t\tprint (\"training...\")\n",
        "\t\tcnn.fit(train_i, train_l, epochs=epochs, batch_size=32, verbose=1, validation_data=(test_i, test_l))\n",
        "\t\t# after training, save the weights.\n",
        "\t\tcnn.save_weights('model_{}_.h5'.format(model_version))\n",
        "\t\n",
        "\t# load the weights if they exist.\n",
        "\tcnn.load_weights('model_{}_.h5'.format(model_version))\n",
        "\t\n",
        "\t# model evaluation. \n",
        "\tloss, acc = cnn.evaluate(test_i, test_l, verbose=0)\n",
        "\tprint (\"model loss {:.1f}%\".format(loss))\n",
        "\tprint (\"model accuracy {:.1f}%\\n\".format(acc))\n",
        "\t\n",
        "\t# print summary if true.\n",
        "\tif summary is True:\n",
        "\t\tprint (\"summary:\")\n",
        "\t\tcnn.summary()\n",
        "\t\n",
        "\tif visualise is True:\n",
        "\t\t# show at least n test results for testing.\n",
        "\t\tn = 10\n",
        "\t\tfor e, i in enumerate(range(n)):\n",
        "\t\t\t# fetch a random image.\n",
        "\t\t\ti, original, gtl = random_image_from_dataset(test_i, test_l)\n",
        "\t\t\tplt.imshow(original)\n",
        "\t\t\tplt.axis('off')\n",
        "\t\t\t\n",
        "\t\t\tprint (\"sample image: {}\\n---\".format(e+1))\n",
        "\t\t\t\n",
        "\t\t\t# get the predicted class and the predicted probabilities.\n",
        "\t\t\tpred_class, prob = (cnn.predict_classes(i, verbose=0)[0], cnn.predict(i, verbose=0).flatten())\n",
        "\t\t\tpredicted_emotion = str(emotions[pred_class])\n",
        "\t\t\tground_truth_emotion = str(emotions[np.argmax(gtl)])\n",
        "\t\t\tconfidence_score = float(prob[pred_class] * 100)\n",
        "\t\t\t\n",
        "\t\t\t# check if the label match the prediction.\n",
        "\t\t\tif ground_truth_emotion is predicted_emotion:\n",
        "\t\t\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"lime\")\n",
        "\t\t\t\tprint (\"image prediction: {} | confidence score: ({:.1f}%)\".format(COLOR['G'] + predicted_emotion + COLOR['RS'], confidence_score))\n",
        "\t\t\telse:\n",
        "\t\t\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"red\")\n",
        "\t\t\t\tprint (\"image prediction: {} | confidence score: ({:.1f}%)\".format(COLOR['R'] + predicted_emotion + COLOR['RS'], confidence_score))\t\n",
        "\t\t\t\t\n",
        "\t\t\t# display the closer emotion probabilities.\n",
        "\t\t\tfor p in np.argsort(-prob):\n",
        "\t\t\t\tprint (\"{}: {:.1f}%\".format(str(emotions[p]), float(prob[p] * 100)))\n",
        "\t\t\t\n",
        "\t\t\t# display the ground truth emotion.\n",
        "\t\t\tprint (\"ground truth: {}\\n\".format(COLOR['G'] + str(ground_truth_emotion) + COLOR['RS']))\n",
        "\t\t\tplt.show()\n",
        "\t\t\tplt.gcf().clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmi_7TuWFCgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the main convolutional neural network architecture.\n",
        "def load_cnn_model():\n",
        "\t# define convnet model.\n",
        "\tcnn = Sequential()\n",
        "\t\n",
        "\t# 3x3 convolution & 2x2 maxpooling with a input image of 60x60x3.\n",
        "\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(3, w, h), name=\"conv_layer_1\"))\n",
        "\tcnn.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_1'))\n",
        "\n",
        "\t# 3x3 convolution & 2x2 maxpooling.\n",
        "\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_layer_2'))\n",
        "\tcnn.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_2'))\n",
        "\n",
        "\t# 3x3 convolution & 9x9 maxpooling.\n",
        "\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_layer_3'))\n",
        "\tcnn.add(MaxPooling2D(pool_size=(9, 9), name='maxpool_3'))\n",
        "\n",
        "\t# dropout 50% and flatten layer.\n",
        "\tcnn.add(Dropout(0.5))\n",
        "\tcnn.add(Flatten(name='flatten_1'))\n",
        "\t\n",
        "\t# fully connected layers and the output layer.\n",
        "\tcnn.add(Dense(512, activation='relu', name='fully_connected_1'))\n",
        "\tcnn.add(Dense(6, activation='softmax', name='output_layer'))\n",
        "\to = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\tcnn.compile(loss='categorical_crossentropy', optimizer=o, metrics=['accuracy'])\n",
        "\t\n",
        "\t# return the cnn model.\n",
        "\treturn cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wElbPN0RFEQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classify an emotion from an image.\n",
        "def classify_emotion_from_image(local_image):\n",
        "\t# classify input image, if it exists.\n",
        "\tif os.path.isfile('model_{}_.h5'.format(model_version)):\n",
        "\t\tprint (\"loading model...\")\n",
        "\t\tcnn = load_cnn_model()\n",
        "\t\tcnn.load_weights('model_{}_.h5'.format(model_version))\n",
        "\t\n",
        "\t\t# load local image.\n",
        "\t\tloaded_img = process_images(local_image)\n",
        "\t\tprint (\"classifying...\")\n",
        "\t\t\n",
        "\t\t# get the predicted class and the predicted probabilities.\n",
        "\t\tpred_class, prob = (cnn.predict_classes(loaded_img, verbose=0)[0], cnn.predict(loaded_img, verbose=0).flatten())\n",
        "\t\tpredicted_emotion = str(emotions[pred_class])\n",
        "\t\tconfidence_score = float(prob[pred_class] * 100)\n",
        "\t\tprint( \"image: {}\\n---\".format(sys.argv[2]))\n",
        "\t\tprint( \"image prediction: {} | confidence score: ({:.1f}%)\".format(COLOR['G'] + predicted_emotion + COLOR['RS'], confidence_score))\n",
        "\t\t\n",
        "\t\t# display the closer emotion probabilities.\n",
        "\t\tfor p in np.argsort(-prob):\n",
        "\t\t\tprint (\"{}: {:.1f}%\".format(str(emotions[p]), float(prob[p] * 100)))\n",
        "\t\t\n",
        "\t\t# display image.\n",
        "\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"purple\")\n",
        "\t\tshow_image(loaded_img)\n",
        "\telse:\n",
        "\t\tprint (\"unable to classify image \\'{}\\', model does not exist, train the network first.\".format(local_image[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV5rqvMlFICa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create visualisations, requires a predefined model.\n",
        "def vis(img):\n",
        "\tif os.path.isfile('model_{}_.h5'.format(model_version)):\n",
        "\t\tprint ('loading model...')\n",
        "\t\tcnn = load_cnn_model()\n",
        "\t\tcnn.load_weights('model_{}_.h5'.format(model_version))\n",
        "\t\t\n",
        "\t\t# list all layers in loaded model.\n",
        "\t\tlayer_name = \"output_layer\"\n",
        "\t\tlayer_idx = [idx for idx, layer in enumerate(cnn.layers) if layer.name == layer_name][0]\n",
        "\t\t\n",
        "\t\t# selected layers to visualise.\n",
        "\t\tlayers = ['conv_layer_1', 'conv_layer_2', 'conv_layer_3', 'output_layer']\n",
        "\t\t\n",
        "\t\t# visualise convnet visualisation for each layer, place them in a subplot.\n",
        "\t\tfor layer_name in layers:\n",
        "\t\t\tprint (\"Generating visualisation of {}\".format(layer_name))\n",
        "\t\t\tlayer_idx = [idx for idx, layer in enumerate(cnn.layers) if layer.name == layer_name][0]\n",
        "\t\t\t\n",
        "\t\t\tif 'conv' not in layer_name:\t\n",
        "\t\t\t\tplt.figure()\n",
        "\t\t\t\tfor idx, e in enumerate(emotions):\n",
        "\t\t\t\t\tplt.subplot(6, 6, idx + 1)\n",
        "\t\t\t\t\tplt.text(1, 7, '{}'.format(e))\n",
        "\t\t\t\t\timg = visualize_activation(cnn, layer_idx, filter_indices=idx, max_iter=750)\n",
        "\t\t\t\t\timg = array_to_img(img.reshape(3, w, h))\n",
        "\t\t\t\t\tplt.axis('off')\n",
        "\t\t\t\t\tplt.imshow(img)\n",
        "\t\t\t\t\n",
        "\t\t\t\tplt.suptitle('Visualisation of the Output Layer')\n",
        "\t\t\t\tplt.savefig('{}.png'.format(layer_name), bbox_inches='tight')\n",
        "\t\t\t\tplt.show()\n",
        "\t\t\t\tbreak\n",
        "\t\t\t\n",
        "\t\t\tfilters = np.arange(get_num_filters(cnn.layers[layer_idx]))\n",
        "\t\t\t\n",
        "\t\t\timages = []\n",
        "\t\t\tfor idx in filters:\n",
        "\t\t\t\timg = visualize_activation(cnn, layer_idx, tv_weight=0, verbose=False, filter_indices=idx, max_iter=750)\n",
        "\t\t\t\timg = array_to_img(img.reshape(3, w, h))\n",
        "\t\t\t\timages.append(img)\n",
        "\t\t\t\n",
        "\t\t\tplt.figure()\n",
        "\t\t\tfor idx, i in enumerate(images):\n",
        "\t\t\t\tplt.subplots_adjust(wspace=0, hspace=0)\n",
        "\t\t\t\tplt.subplot(6, 6, idx + 1)\n",
        "\t\t\t\tplt.text(0, 15, 'Filter {}'.format(idx) )\n",
        "\t\t\t\tplt.axis('off')\n",
        "\t\t\t\tplt.imshow(i)\n",
        "\t\t\t\t\n",
        "\t\t\tplt.suptitle('Visualisation of Convolution Layer {}'.format(layer_name[len(layer_name)-1]))\n",
        "\t\t\tplt.savefig('{}.png'.format(layer_name), bbox_inches='tight')\n",
        "\t\t\tplt.show()\n",
        "\t\t\t\n",
        "\telse:\n",
        "\t\tprint ('model does not exist, train the network first.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfdYNoirFO40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\tsetup(False)\n",
        "\tK.set_image_data_format('channels_first')\n",
        "\tvisualise_classification = True\n",
        "\tsummary = True\n",
        "\ttrain_i, train_l, test_i, test_l = load_training_and_testing_data()\n",
        "\ttrain(train_i, train_l, test_i, test_l, visualise_classification, summary)\n",
        "\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKHAD0pvZ2eZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}